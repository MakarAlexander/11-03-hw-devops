# Домашнее задание к занятию «Микросервисы: подходы» "Макарцев Александр Владимирович"

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

#### Решение
1) Базовое решение: **GitLab**, позволяет покрыть все требования. Для обеспечения требований достаточно Community Edition (CE), но Enterprise будет предпочтительнее для больших команд разработки и сложных продуктов.  
По требованиям:
   - cloud-native изначально. В Yandex Cloud есть GitLab Managed Service, можно также развернуть cloud-native версию (микросервисную) в своем k8s кластере через Helm-chart или Operator, либо же выделить Linux-сервер под Omnibus version;  
   - основывается на Git и в добавок для управления хранилищем использует Gitaly;
   - нет ограничения по репозиториям;
   - есть полноценный GitLab CI/CD, гибкая настройка запуска пайплайнов по событию в git (commit, MR), по расписанию, вручную с параметрами и downstream pipelines по событию в другом проекте и т.д.;
   - параметры можно задавать на проекте, группе или в общей системе, в остальном параметры и порядок (шаблон) сборки регулируются в пайплайне. Пайплайн обычно находится отдельно от основного проекта;
   - есть возможность в парамметрах проекта или группы проектов хранить секреты, которые при запуске джобов будут скрыты, но также можно использовать внешнее хранилище секретов Vault и настроить взаимодействие раннеров с ним по JWT;
   - несколько конфигураций для сборки из одного репозитория возможно реализовать, настроив логику в пайплайне (например, в разрезе Deployments). Все шаги (джобы) полностью кастомизируются;
   - GitLab Runners могут использовать docker engine для выполнения джобов пайплайна, и джобы пишутся скриптовыми языками, что почти безгранично расширяет возможности. Можно использовать любой набор инструментов и кастомизировать сборку;
   - GitLab Runners могут располагаться как в облаке, так и на собственных серверах;
   - т.к. раннеры не ограничены в количестве, и каждый из них имеет concurrency режим, то все джобы могут выполняться параллельно, нужно лишь обеспечить необходимые ресурсы;
   - есть свои хранилища Package Registry (pypi, maven, helm и т.д.), а также Container Registry для хранения собранных образов Docker.  Каждая сборка позволяет сохранять артефакты пайплайна.


2) Продвинутое решение:
    - GitLab - как система контроля версий, управление проектами, репозитории, CI/CD
    - Hashicorp Vault - для хранения секретов
    - Sonatype Nexus - для хранения артефактов 
    - Также можно вынести CI/CD из Gitlab и использовать для этого Jenkins - в случае, если для кастомизации и конфигурации сборок не хватило возможностей GitLab. 

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

#### Решение
Сложилось ощущение, что стандартом на данный момент является использование стека ELK.

Filebeat + logstash обеспечит сбор данных из stdout.
Filebeat также может обеспечить повторную отправку логов при недоступности. Дополнительно можно использовать брокер сообщений для промежуточного хранения логов (по типу Kafka).
Elasticsearch обеспечивает хранение, поиск и фильтрацию.
Kibana обеспечит интерфейс пользователям, позволит делиться фильтрами.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

#### Решение
Популярным решением будет Prometheus + VictoriaMetrics для долговременного хранения метрик + Grafana для визуализации. И в целом все решения будут основаны на визуализации Grafana и покрывать основные требования.

1. Стек **VictoriaMetrics + Grafana**
   - Victoria Metrics уже развились до полноценной замены prometheus, их решение более эффективное и масштабируемое в cloud-native среде. Состоит из множества компонент
   - vmagent работает стабильнее Prometheus, т.к. функционал разделен с другими компонентами
   - очень эффективно хранит большие объемы данных

2. Zabbix + Zabbix Agent собирает и отправляет нужные метрики, в Zabbix их предоставляет в нужном нам виде.

Zabbix выглядит более простым для настройки, а VictoriaMetrics + Grafana – более гибким и чаще рекомендуется для микросервисов.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---